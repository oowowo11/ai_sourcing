import os
import streamlit as st
import openai
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import openpyxl
import urllib.parse
import time
from datetime import datetime
import os

# 1) OpenAI í‚¤
openai.api_key = os.environ.get("OPENAI_API_KEY")
if not openai.api_key:
    st.error("OPENAI_API_KEY ì„¤ì • í•„ìš”!")
    st.stop()

# 2. ì—‘ì…€ í…œí”Œë¦¿ íŒŒì¼ëª… (í•„ìš”ì— ë”°ë¼ ê²½ë¡œ ìˆ˜ì •)
taobao_template = "123.xlsx"
rakuten_template = "123.xlsx"

def setup_driver(lang):
    options = Options()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--disable-infobars")
    options.add_argument("start-maximized")
    if lang == "zh-CN":
        options.add_argument("--lang=zh-CN")
    else:
        options.add_argument("--lang=ja-JP")
    options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36")
    driver = webdriver.Chrome(options=options)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": """
        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
        window.navigator.chrome = { runtime: {} };
        Object.defineProperty(navigator, 'languages', {get: () => ['zh-CN', 'zh']});
        Object.defineProperty(navigator, 'plugins', {get: () => [1,2,3,4,5]});
        """ if lang == "zh-CN" else """
        Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
        window.navigator.chrome = { runtime: {} };
        Object.defineProperty(navigator, 'languages', {get: () => ['ja-JP', 'ja']});
        Object.defineProperty(navigator, 'plugins', {get: () => [1,2,3,4,5]});
        """
    })
    return driver

def generate_keywords(category, target, n, market):
    # system, prompt êµ¬ì„±ì€ ê·¸ëŒ€ë¡œ ë‘¡ë‹ˆë‹¤.
    if market == "íƒ€ì˜¤ë°”ì˜¤":
        system = "You are an expert in Chinese cross-border e-commerce trend analysis. Please respond in Korean."
        prompt = (
            f"Recommend {n} trending premium products in category '{category}' "
            f"for audience '{target}'. "
            "Provide each item as <Korean> â€“ <Chinese>."
        )
    else:
        system = "You are an expert in Japanese e-commerce fashion trends. Please respond in Korean."
        prompt = (
            f"Recommend {n} popular product keywords for Rakuten Brand Avenue "
            f"in category '{category}', target '{target}'. "
            "Return each as (Korean, Japanese) lines."
        )

    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": "gpt-4o",
        "messages": [
            {"role":"system", "content": system},
            {"role":"user",   "content": prompt}
        ],
        "max_tokens": 300,
        "temperature": 0.7
    }

    try:
        r = requests.post(url, headers=headers, json=data, timeout=60)
        r.raise_for_status()
        resp = r.json()
        text = resp["choices"][0]["message"]["content"].strip()
    except Exception as e:
        st.error("â—ï¸ OpenAI í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.write("ğŸ” ìƒì„¸ ì˜¤ë¥˜ ë©”ì‹œì§€:", e)
        return []

    # â”€â”€ ì—¬ê¸°ë¶€í„°ëŠ” ì •ìƒ response ì²˜ë¦¬ ë¡œì§ â”€â”€
    pairs = []
    for line in text.splitlines():
        if market=="íƒ€ì˜¤ë°”ì˜¤" and "â€“" in line:
            ko, zh = [s.strip() for s in line.split("â€“",1)]
            pairs.append((ko, zh))
        elif market=="ë¼ì¿ í…" and "," in line:
            ko, ja = [x.strip(" ()") for x in line.split(",",1)]
            pairs.append((ko, ja))
    return pairs[:n]

def crawl_links_http(keyword, num_links, market):
    headers = {"User-Agent":"Mozilla/5.0"}
    if market=="íƒ€ì˜¤ë°”ì˜¤":
        url = f"https://world.taobao.com/search/search.htm?q={urllib.parse.quote(keyword)}"
    else:
        url = "https://brandavenue.rakuten.co.jp/all-sites/item/" + \
              f"?free_word={urllib.parse.quote(keyword)}&sale=0&inventory_flg=1"
    resp = requests.get(url, headers=headers, timeout=30)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "html.parser")
    links = []
    if market=="íƒ€ì˜¤ë°”ì˜¤":
        for a in soup.select("a[href]"):
            href=a["href"]
            if "item.taobao.com" in href or "detail.tmall.com" in href:
                links.append(href)
            if len(links)>=num_links: break
    else:
        for a in soup.select("a[href*='brandavenue.rakuten.co.jp/item']"):
            links.append(a["href"])
            if len(links)>=num_links: break
    return list(dict.fromkeys(links))[:num_links]

def save_links_to_excel(links, batch_idx, category, market, template):
    today = datetime.now().strftime("%Y%m%d")
    safe_category = category.replace(" ", "_")
    filename = f"{market}_{safe_category}_{today}_batch{batch_idx}.xlsx"
    wb = openpyxl.load_workbook(template)
    sheet = wb.active
    for i, link in enumerate(links):
        sheet[f'B{i + 4}'] = link
    wb.save(filename)
    return filename

def main():
    st.title("ë§ˆì¼“ ì†Œì‹± ìë™í™” í”„ë¡œê·¸ë¨ (ì›¹ë²„ì „)")

    market = st.selectbox("ë§ˆì¼“ ì„ íƒ", ["íƒ€ì˜¤ë°”ì˜¤", "ë¼ì¿ í…"])
    category = st.text_input("ì¹´í…Œê³ ë¦¬ ì…ë ¥ (ì˜ˆ: ì—¬ë¦„ ì—¬ì„± ì˜ë¥˜)")
    target = st.text_input("íƒ€ê¹ƒ(ëŒ€ìƒ) ì…ë ¥ (ì˜ˆ: 20~40ëŒ€ ì—¬ì„±)")
    num_keywords = st.number_input("ì¹´í…Œê³ ë¦¬ë‹¹ ìƒì„±í•  í‚¤ì›Œë“œ ê°œìˆ˜", min_value=1, max_value=20, value=3)
    num_links = st.number_input("í•œ í‚¤ì›Œë“œë‹¹ í¬ë¡¤ë§í•  ë§í¬ ê°œìˆ˜", min_value=1, max_value=20, value=10)

    run = st.button("ì‹¤í–‰")

    if run:
    
        # ì…ë ¥ ê²€ì‚¬ â€¦
        kws = generate_keywords(category, target, num_keywords, market)
        # â€¦
        all_links=[]; batch=1; files=[]
        for ko, keyword in kws:
            st.write(f"ğŸ” {keyword} í¬ë¡¤ë§ ì¤‘â€¦")
            links = crawl_links_http(keyword, num_links, market)
        st.success("ëª¨ë“  ì‘ì—… ì™„ë£Œ! ì•„ë˜ì—ì„œ ê²°ê³¼ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”:")
        for fname in filenames:
            if os.path.exists(fname):
                st.write(f"ğŸ“ {fname}")

if __name__ == "__main__":
    main()
